{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "實作本篇提到的三大概念\n",
    "\n",
    "- 翻轉：實作上下左右的翻轉\n",
    "- 縮放：比較鄰近差值與雙立方插值 (或雙線性插值) 的圖片品質\n",
    "- 平移：建立 Translation Transformation Matrix 來做平移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Using lena.png\n",
    "img = 'img/lena.png'\n",
    "\n",
    "# default read as cv2.IMREAD_COLOR(彩色圖)\n",
    "img_bgr = cv2.imread(img, cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上下左右翻轉圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertical flip(垂直翻轉)\n",
    "# img_bgr[h, w, channel], h reversed which means vertical flip\n",
    "img_vflip = img_bgr[::-1, :, :]\n",
    "\n",
    "# horizontal flip(水平翻轉)\n",
    "# img_bgr[h, w, channel], w reversed which means horizontal flip\n",
    "img_hflip = img_bgr[:, ::-1, :]\n",
    "\n",
    "# vertical flip + horizontal flip(垂直+水平翻轉)\n",
    "img_vhflip = img_bgr[::-1, ::-1, :]\n",
    "\n",
    "# 縱向組合圖片\n",
    "img_vflip_new = np.vstack((img_bgr, img_vflip))\n",
    "\n",
    "# 橫向組合圖片\n",
    "img_hflip_new = np.hstack((img_bgr, img_hflip))\n",
    "\n",
    "# 橫向組合圖片(vhflip)\n",
    "img_vhflip_new = np.hstack((img_bgr, img_vhflip))\n",
    "\n",
    "while True :\n",
    "    # display of img_vflip_new, named as 'vertical flip'\n",
    "    cv2.imshow('vertical flip', img_vflip_new)\n",
    "    # display of img_hflip_new, named as 'horizontal flip'\n",
    "    cv2.imshow('horizontal flip', img_hflip_new)\n",
    "    # display of img_vhflip_new, named as 'v+h flip'\n",
    "    cv2.imshow('v+h flip', img_vhflip_new)\n",
    "    \n",
    "    # waiting until to press any key then close the display window\n",
    "    if cv2.waitKey(0) : \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 縮放圖片\n",
    "\n",
    "- 先透過縮小圖片去壓縮原有圖片保有的資訊，再放大比較不同方法之間的速度與圖片品質\n",
    "- case1 : downscale and then upscale\n",
    "- case2 : original image scale up directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTER_NEAREST zoom time consumed : 0:00:00.000998\n",
      "INTER_CUBIC zoom time consumed : 0:00:00.002992\n",
      "(512, 512, 3)\n",
      "(612, 612, 3)\n"
     ]
    }
   ],
   "source": [
    "# case1 : downscale and then upscale\n",
    "from datetime import datetime\n",
    "\n",
    "# (1)downscale to 20% of image\n",
    "# second argument set to None, and fx depend on width, fy depend on height(or second argument set to (width, height))\n",
    "img_down = cv2.resize(img_bgr, None, fx=0.2, fy=0.2)\n",
    "\n",
    "# (2)upscale to 6 times from step(1), that means scale to 1.2 * original image\n",
    "fx, fy = 6, 6\n",
    "\n",
    "# 鄰近差值的插補法 + 計算花費時間\n",
    "start_time = datetime.now()\n",
    "img_up_NEAREST = cv2.resize(img_down, None, fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
    "print('INTER_NEAREST zoom time consumed : {}'.format(datetime.now() - start_time))\n",
    "\n",
    "# INTER_CUBIC的插補法 + 計算花費時間\n",
    "start_time = datetime.now()\n",
    "img_up_CUBIC = cv2.resize(img_down, None, fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)\n",
    "print('INTER_CUBIC zoom time consumed : {}'.format(datetime.now() - start_time))\n",
    "\n",
    "print(img_bgr.shape)        # original image\n",
    "print(img_up_NEAREST.shape) # scaling up image\n",
    "\n",
    "# 橫向組合圖片\n",
    "img_up_new = np.hstack((img_up_NEAREST, img_up_CUBIC))\n",
    "\n",
    "while True :\n",
    "    # display of img_up_new, named as 'image zoom'\n",
    "    cv2.imshow('image zoom', img_up_new)\n",
    "    \n",
    "    # waiting until to press any key then close the display window\n",
    "    if cv2.waitKey(0) : \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTER_NEAREST zoom time consumed : 0:00:00.000996\n"
     ]
    }
   ],
   "source": [
    "# case2 : original image scale up directly\n",
    "from datetime import datetime\n",
    "\n",
    "# (1)downscale to 20% of image\n",
    "# second argument set to None, and fx depend on width, fy depend on height(or second argument set to (width, height))\n",
    "img_down = cv2.resize(img_bgr, None, fx=0.2, fy=0.2)\n",
    "\n",
    "# (2)upscale to 6 times from step(1), that means scale to 1.2 * original image\n",
    "fx, fy = 6, 6\n",
    "\n",
    "# 鄰近差值的插補法 + 計算花費時間\n",
    "start_time = datetime.now()\n",
    "img_up_NEAREST = cv2.resize(img_down, None, fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
    "print('INTER_NEAREST zoom time consumed : {}'.format(datetime.now() - start_time))\n",
    "\n",
    "# original image scale up directly (reaize to (width, height))\n",
    "img_origin_up = cv2.resize(img_bgr, (img_up_NEAREST.shape[1], img_up_NEAREST.shape[0]))\n",
    "\n",
    "# 橫向組合圖片\n",
    "img_up_new = np.hstack((img_origin_up, img_up_NEAREST))\n",
    "\n",
    "while True :\n",
    "    # display of img_up_new, named as 'image zoom'\n",
    "    cv2.imshow('image zoom', img_up_new)\n",
    "    \n",
    "    # waiting until to press any key then close the display window\n",
    "    if cv2.waitKey(0) : \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平移幾何轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 Translation Transformation Matrix ([[1,0,tx], [0,1,ty]]), x move 100 pixels, y move 50 pixels\n",
    "M = np.float32([[1,0,100], [0,1,50]])\n",
    "# cv2.warpAffine(img, TT Matrix, dsize=(width, height))\n",
    "img_shift = cv2.warpAffine(img_bgr, M, (img_bgr.shape[1], img_bgr.shape[0]))\n",
    "\n",
    "# 橫向組合圖片\n",
    "img_shift_new = np.hstack((img_bgr, img_shift))\n",
    "\n",
    "while True :\n",
    "    # display of img_shift_new, named as 'image shift'\n",
    "    cv2.imshow('image shift', img_shift_new)\n",
    "    \n",
    "    # waiting until to press any key then close the display window\n",
    "    if cv2.waitKey(0) : \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
