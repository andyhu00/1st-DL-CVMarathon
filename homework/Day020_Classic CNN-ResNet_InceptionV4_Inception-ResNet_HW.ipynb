{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 學習如何搭建 Residual Block\n",
    "####  學習如何搭建Inception-ResNet中的 Inception Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解 Residual Block原理\n",
    "  #### 了解如何結合Inception 與 Residual概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incpeiton](img/ResNet_Structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetV1版本的Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Original (2 convolution layer) :\n",
    "def Residual_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)  # weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)  # weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考ResNetV1 搭建 ResNetV2版本的Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet full pre-activation :\n",
    "def Residual_block_v2(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # build Residual_V2 Block\n",
    "    # BN before each weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2a')(x)  # weight layer\n",
    "\n",
    "    # BN before each weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2b')(x)  # weight layer\n",
    "\n",
    "    # remove Relu\n",
    "    x = layers.add([x, input_tensor])\n",
    "    #x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 試試看自己設計一個先壓縮再回放的V2 Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce and recover filters with Residual-V2\n",
    "def Residual_block_v2(input_tensor, kernel_size, stage, block, reduec=64, output_size=128):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # reduce filters with kernel_size=(1,1)\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(reduec, (1, 1), padding='same', name=conv_name_base + '2a')(x)  # weight layer\n",
    "\n",
    "    # reduce filters with kernel_size=kernel_size\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(reduec, kernel_size, name=conv_name_base + '2b')(x)  # weight layer\n",
    "\n",
    "    # recover filters with kernel_size=(1,1)\n",
    "    x = Conv2D(output_size, (1, 1), padding='same', name=conv_name_base + '2a')(x)  # weight layer\n",
    "    \n",
    "    # remove Relu\n",
    "    x = layers.add([x, input_tensor])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incpetion Block-A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incpeiton](img/Inception-ResNet-A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incpetion Block-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incpeiton](img/Inception-ResNet-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incpetion Block-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incpeiton](img/Inception-ResNet-C.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding = 'same', strides = (1,1), let h,w of output keep same as h,w of input \n",
    "def Conv2d_bn(x,filters,kernel_size,padding='same',strides=(1, 1),normalizer=True,activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        conv_name = name + '_conv'\n",
    "        bn_name = name + '_bn'\n",
    "        act_name = name + '_act'\n",
    "    else:\n",
    "        conv_name = None\n",
    "        bn_name = None\n",
    "        act_name = None\n",
    "    # 'channels_first' : corresponds to inputs with shape (batch_size, channels, height, width)\n",
    "    # 'channels_last'  : corresponds to inputs with shape (batch_size, height, width, channels)\n",
    "    if K.image_data_format() == 'channels_first':  \n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(\n",
    "            filters, kernel_size,\n",
    "            strides=strides, padding=padding,\n",
    "            use_bias=False, name=conv_name)(x)\n",
    "    if normalizer:\n",
    "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    if activation:\n",
    "        x = Activation(activation, name=act_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Original (3 convolution layer) :\n",
    "def Residual_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)  # weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)  # weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)  # weight layer\n",
    "    x = BatchNormalization(axis=3, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考上方Residual_block搭建 Inception-ResNet中的Inception Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnet_block(x, scale, block_type, activation='relu'):\n",
    "    '''scale: scaling factor to scale the residuals (i.e., the output of\n",
    "            passing `x` through an inception module) before adding them\n",
    "            to the shortcut branch. Let `r` be the output from the residual branch,\n",
    "            the output of this block will be `x + scale * r`.(簡單來說就是控制Residual branch的比例)'''\n",
    "    \n",
    "    # inception block :\n",
    "    if block_type == 'Incpetion_Block-A':\n",
    "        branch_0 = Conv2d_bn(x, 32, 1)\n",
    "        branch_1 = Conv2d_bn(x, 32, 1)\n",
    "        branch_1 = Conv2d_bn(branch_1, 32, 3)\n",
    "        branch_2 = Conv2d_bn(x, 32, 1)\n",
    "        branch_2 = Conv2d_bn(branch_2, 48, 3)\n",
    "        branch_2 = Conv2d_bn(branch_2, 64, 3)\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'Incpetion_Block-B':\n",
    "        branch_0 = Conv2d_bn(x, 192, 1)\n",
    "        branch_1 = Conv2d_bn(x, 128, 1)\n",
    "        branch_1 = Conv2d_bn(branch_1, 160, [1, 7])\n",
    "        branch_1 = Conv2d_bn(branch_1, 192, [7, 1])\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'Incpetion_Block-C':\n",
    "        branch_0 = Conv2d_bn(x, 192, 1)\n",
    "        branch_1 = Conv2d_bn(x, 192, 1)\n",
    "        branch_1 = Conv2d_bn(branch_1, 192, [1, 3])\n",
    "        branch_1 = Conv2d_bn(branch_1, 192, [3, 1])\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"block35\", \"block17\" or \"block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "    \n",
    "    mixed = Concatenate(axis=3)(branches)  # = layers.concatenate(branches, axis=3)\n",
    "    # assume input shape x = (None, 224, 224, 32)\n",
    "    # assume block_type == 'Incpetion_Block-A', mixed output shape=(None, 224, 224, 128)\n",
    "    \n",
    "    '''確保輸入跟輸出深度相同'''\n",
    "    # Conv2d_bn(img_input, filters, kernel_size)\n",
    "    # input=mixed, filters=32, kernel_size=1, output shape=(None, 224, 224, 32), output depth neet to be same as input=32\n",
    "    up = Conv2d_bn(mixed, K.int_shape(x)[3], 1, activation=None)\n",
    "    \n",
    "    ''' 導入Residual Block殘差結構，並給予權重scale '''\n",
    "    # Lambda(function, output_shape=None, mask=None, arguments=None)\n",
    "    # inputs=[x, up], means input[0]=x, input[1]=up, so Residual Block x = x + up*(scale)\n",
    "    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "               output_shape = K.int_shape(x)[1:],     # (224, 224, 32)\n",
    "               arguments = {'scale': scale})([x, up]) \n",
    "                                                      \n",
    "    if activation is not None:\n",
    "        x = Activation(activation)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_14/Relu:0\", shape=(None, 224, 224, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(224,224,32))  \n",
    "x = inception_resnet_block(img_input, 0.1, 'Incpetion_Block-A', activation='relu')\n",
    "print(x)  # shape=(None, 224, 224, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_19/Relu:0\", shape=(None, 224, 224, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(224,224,32))  \n",
    "x = inception_resnet_block(img_input, 0.1, 'Incpetion_Block-B', activation='relu')\n",
    "print(x)  # shape=(None, 224, 224, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_24/Relu:0\", shape=(None, 224, 224, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(224,224,32))  \n",
    "x = inception_resnet_block(img_input, 0.1, 'Incpetion_Block-C', activation='relu')\n",
    "print(x)  # shape=(None, 224, 224, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嘗試導入Inception Block到 Vgg_Inception中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
