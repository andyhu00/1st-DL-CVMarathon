{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras-ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 學習使用Keras-ImageDataGenerator 與 Imgae Augmentation 做圖像增強"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉Image Augmentation的實作方法\n",
    "  #### 瞭解如何導入Imgae Augmentation到原本NN架構中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一 Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3ff7e3b91402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img/Tano.JPG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#  resize img to (224, 224)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# cv2 original is BGR，convert to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mimg_origin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# img_origin is RGB (224,224,3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "# define Augmentation, img_gen is a generator\n",
    "img_gen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, rotation_range=10, \n",
    "                             width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1,\n",
    "                             horizontal_flip=True, vertical_flip=False, dtype=np.float32)\n",
    "width = 224\n",
    "height = 224\n",
    "batch_size = 4\n",
    "\n",
    "img = cv2.imread('img/Tano.JPG')  \n",
    "img = cv2.resize(img, (width, height)) #  resize img to (224, 224)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 original is BGR，convert to RGB\n",
    "img_origin = img.copy() # img_origin is RGB (224,224,3)\n",
    "img = np.array(img, dtype=np.float32) # img is (224,224,3)\n",
    "img_combine = np.array([img,img,img,img], dtype=np.uint8) # let (224,224,3) become to (4,224,224,3)\n",
    "batch_gen = img_gen.flow(img_combine, batch_size=4)       # batch_gen is a iterator\n",
    "\n",
    "assert next(batch_gen).shape==(batch_size, height, width, 3)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for batch,i in zip(batch_gen, [2,3,4,5]) :\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(img_origin) # 第1張: original image (RGB)\n",
    "    \n",
    "    plt.subplot(1, 5, i)   # 第2~5張\n",
    "    plt.imshow(batch[0, :, :, :].astype(np.uint8))  # batch_0\n",
    "    plt.imshow(batch[1, :, :, :].astype(np.uint8))  # batch_1\n",
    "    plt.imshow(batch[2, :, :, :].astype(np.uint8))  # batch_2\n",
    "    plt.imshow(batch[3, :, :, :].astype(np.uint8))  # batch_3\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示範如何導入ImageDataGenerator到Keras訓練中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系統找不到指定的路徑。: 'img/training_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-74934a8cd5c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                                                  class_mode = 'categorical')\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m test_set = test_data_gen.flow_from_directory('img/test_set',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             dtype=dtype)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系統找不到指定的路徑。: 'img/training_set'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10          # for Downloading cifar10 data set \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import regularizers\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "# 建立 CNN 層模型 (Build CNN model)\n",
    "classifier = Sequential()\n",
    "\n",
    "# 1st convolution layer(input layer) :\n",
    "# Convolution2D(numbers of convolution kernel, kernel_row, kernel_column)\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape)) \n",
    "# output_shape=(None, 32, 32, 32)\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "# BatchNormalization : normalize the input\n",
    "\n",
    "classifier.add(BatchNormalization()) #output_shape=(None, 16, 16, 32)\n",
    "\n",
    "# 2nd convolution layer(hidden layer) \n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')) # output_shape=(None, 16, 16, 32)\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "# 2nd convolution layer:Total params(參數量)=(Kernel_row*column*channels+1)*Kernel numbers(kernel張數)=(3*3*32+1)*32=9248\n",
    "\n",
    "# BatchNormalization : normalize the input\n",
    "classifier.add(BatchNormalization())  #output_shape=(None, 8, 8, 32)\n",
    "\n",
    "classifier.add(Flatten())  #output_shape=(None, 2048),\n",
    "\n",
    "# FC layer (1st layer)\n",
    "classifier.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.001))) \n",
    "# output_shape=(None, 100)\n",
    "\n",
    "# BatchNormalization : normalize the input\n",
    "classifier.add(BatchNormalization()) # output_shape=(None, 100) \n",
    "\n",
    "# dropout rate : 50 %\n",
    "classifier.add(Dropout(rate=0.5)) # output_shape=(None, 100)\n",
    "\n",
    "# FC layer (2nd layer)\n",
    "classifier.add(Dense(units=100, activation='relu', kernel_regularizer=regularizers.l2(0.001))) \n",
    "# output_shape=(None, 100)\n",
    "\n",
    "# BatchNormalization : normalize the input\n",
    "classifier.add(BatchNormalization()) # output_shape=(None, 100) \n",
    "\n",
    "# dropout rate : 30 %\n",
    "classifier.add(Dropout(rate=0.3))  # output_shape=(None, 100)\n",
    "\n",
    "# FC layer (output layer) \n",
    "classifier.add(Dense(units=2, activation='softmax')) \n",
    "# output_shape=(None, 2)\n",
    "\n",
    "## =============================================================\n",
    "\n",
    "#Training Generator\n",
    "train_data_gen = ImageDataGenerator(rescale = 2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "#Test Generator，只需要Rescale，不需要其他增強\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_data_gen.flow_from_directory('img/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 8,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_data_gen.flow_from_directory('img/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 8,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "# training model \n",
    "batch_size_1 = 4\n",
    "\n",
    "# compile( 優化器:optimizer='adam', 損失函數loss function:categorical_crossentropy, 模型評估指標:metrics=['accuracy'] )\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# EarlyStopping() \n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=8, verbose=1) # earlystop\n",
    "\n",
    "classifier.fit_generator(training_set, steps_per_epoch = len(next(training_set)[0]) / batch_size_1, epochs = 20,\n",
    "                         validation_data = test_set, validation_steps = len(next(test_set)[0]) / batch_size_1,\n",
    "                         callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測新照片\n",
    "from keras.preprocessing import image as image_utils\n",
    "# PIL image\n",
    "test_image = image_utils.load_img('img/new_images/new_picture.jpg', target_size=(64, 64)) \n",
    "print(test_image)\n",
    "test_image = image_utils.img_to_array(test_image) # image to array (3D), (64,64,3)\n",
    "print(test_image.shape)\n",
    "test_image = np.expand_dims(test_image, axis=0)   # 3D expand to 4D (1,64,64,3)\n",
    "print(test_image.shape)\n",
    "\n",
    "\n",
    "result = classifier.predict_on_batch(test_image)\n",
    "result  # input class is dog, and result get the probability  is dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習使用Image Augmentation\n",
    "- 使用單項增強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Tano.JPG')  \n",
    "img = cv2.resize(img, (224,224))##改變圖片尺寸\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #Cv2讀進來是BGR，轉成RGB\n",
    "img_origin=img.copy()\n",
    "img= np.array(img, dtype=np.float32)\n",
    "\n",
    "images = np.random.randint(0, 255, (5, 224, 224, 3), dtype=np.uint8)##創造一個array size==(5, 224, 224, 3)\n",
    "\n",
    "flipper = iaa.Fliplr(1.0) #水平翻轉機率==1.0\n",
    "images[0] = flipper.augment_image(img) \n",
    "\n",
    "vflipper = iaa.Flipud('''填入''') #垂直翻轉機率40%\n",
    "images[1] = vflipper.augment_image(img) \n",
    "\n",
    "blurer = iaa.GaussianBlur(3.0)\n",
    "images[2] = blurer.augment_image(img) # 高斯模糊圖像( sigma of 3.0)\n",
    "\n",
    "translater = iaa.Affine(translate_px={\"x\": -16}) #向左橫移16個像素\n",
    "images[3] = translater.augment_image(img) \n",
    "\n",
    "scaler = iaa.Affine(scale={\"y\":'''填入'''}) # 縮放照片，區間(0.8-1.2倍)\n",
    "images[4] = scaler.augment_image(img)\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(20,20))\n",
    "for image in images:\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(img_origin.astype(np.uint8))\n",
    "    plt.subplot(1, 6, i+1)\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打包多種Augmentation\n",
    "#### 請自行練習新增以及改變Augmentation內容\n",
    "#### 可參考Github: https://github.com/aleju/imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包裝自定義Augmentation 與 Imgaug Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鎖住隨機性-主要用在Semantic segmentation中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
